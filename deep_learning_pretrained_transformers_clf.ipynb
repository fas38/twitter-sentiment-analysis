{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "team_id = '20' #put your team id here\n",
    "split = 'test_1' # replace by 'test_2' for FINAL submission\n",
    "\n",
    "df = pd.read_csv('dataset/tweets_train.csv')\n",
    "df_test = pd.read_csv(f'dataset/tweets_{split}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_str'] = df['words'].apply(lambda words: ' '.join(eval(words)))\n",
    "df_test['words_str'] = df_test['words'].apply(lambda words: ' '.join(eval(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@xbresson British Alps :-)</td>\n",
       "      <td>british alps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Aistats2020: Videos presentations of paper...</td>\n",
       "      <td>videos presentations papers keynote talks aist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I hope I would be able to talk more about this...</td>\n",
       "      <td>hope would able talk balcony tomorrow pm et al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @dlbcnai: Keynote by Joan Bruna (@joanbruna...</td>\n",
       "      <td>keynote joan bruna geometric deep learning pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@annargrs @Michael_J_Black @AllenHW0 @CSProfKG...</td>\n",
       "      <td>process science relies much basic honesty part...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                         @xbresson British Alps :-)   \n",
       "1  RT @Aistats2020: Videos presentations of paper...   \n",
       "2  I hope I would be able to talk more about this...   \n",
       "3  RT @dlbcnai: Keynote by Joan Bruna (@joanbruna...   \n",
       "4  @annargrs @Michael_J_Black @AllenHW0 @CSProfKG...   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0                                       british alps  \n",
       "1  videos presentations papers keynote talks aist...  \n",
       "2  hope would able talk balcony tomorrow pm et al...  \n",
       "3  keynote joan bruna geometric deep learning pro...  \n",
       "4  process science relies much basic honesty part...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the preprocess function as provided earlier\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Applying the preprocessing function to the 'text' column of the training data again\n",
    "df['preprocessed_text'] = df['words_str'].apply(preprocess)\n",
    "\n",
    "# Displaying the first few rows to check the preprocessing\n",
    "df[['text', 'preprocessed_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task and model path\n",
    "task = 'sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "# Initializing the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# Downloading label mapping\n",
    "labels = []\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# Loading the PyTorch model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Tokenizing the preprocessed text using the initialized tokenizer\n",
    "encoded_train_input = tokenizer(df['preprocessed_text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Displaying the keys of the encoded input to confirm the tokenization\n",
    "encoded_train_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from scipy.special import softmax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6021846321800873"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Making predictions using the model\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded_train_input)\n",
    "    logits = output[0]  # Keeping logits on the same device as the model\n",
    "\n",
    "# Moving logits to CPU to apply softmax and other operations\n",
    "logits = logits.cpu().numpy()\n",
    "\n",
    "# Applying softmax to obtain probabilities\n",
    "probabilities = softmax(logits, axis=1)\n",
    "\n",
    "# Getting the predicted labels\n",
    "predicted_labels = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Converting string labels to integers for the true labels\n",
    "label_mapping = {label: idx for idx, label in enumerate(labels)}\n",
    "true_labels = df['sentiment'].map(label_mapping).values\n",
    "\n",
    "# Calculating the F1 macro score\n",
    "f1_macro = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "f1_macro\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlStuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
